{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy LLaVA on Amazon SageMaker\n",
    "\n",
    "Amazon SageMaker is a popular platform for running AI models, and models on huggingface deploy [Hugging Face Transformers](https://github.com/huggingface/transformers) using [Amazon SageMaker](https://docs.aws.amazon.com/sagemaker/latest/dg/whatis.html) and the [Amazon SageMaker Python SDK](https://sagemaker.readthedocs.io/en/stable/).\n",
    "\n",
    "![llava](https://i.imgur.com/YNVG140.png)\n",
    "\n",
    "Install sagemaker sdk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (2.219.0)\n",
      "Collecting sagemaker\n",
      "  Using cached sagemaker-2.221.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (23.2.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.33.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (1.34.101)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (2.2.1)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (1.26.4)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.12 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (4.25.3)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (6.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (21.3)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (1.5.3)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (0.3.2)\n",
      "Requirement already satisfied: schema in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (0.7.5)\n",
      "Requirement already satisfied: PyYAML~=6.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (6.0.1)\n",
      "Requirement already satisfied: jsonschema in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (4.21.1)\n",
      "Requirement already satisfied: platformdirs in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (4.2.0)\n",
      "Requirement already satisfied: tblib<4,>=1.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (3.0.0)\n",
      "Requirement already satisfied: urllib3<3.0.0,>=1.26.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (2.2.1)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (2.31.0)\n",
      "Requirement already satisfied: docker in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (6.1.3)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (4.66.2)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (5.9.8)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.101 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3<2.0,>=1.33.3->sagemaker) (1.34.101)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3<2.0,>=1.33.3->sagemaker) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3<2.0,>=1.33.3->sagemaker) (0.10.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker) (3.17.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->sagemaker) (3.1.2)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from docker->sagemaker) (1.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->sagemaker) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->sagemaker) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->sagemaker) (2024.2.2)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from google-pasta->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->sagemaker) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->sagemaker) (0.34.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->sagemaker) (0.18.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->sagemaker) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->sagemaker) (2024.1)\n",
      "Requirement already satisfied: ppft>=1.7.6.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker) (1.7.6.8)\n",
      "Requirement already satisfied: dill>=0.3.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.8)\n",
      "Requirement already satisfied: pox>=0.3.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.4)\n",
      "Requirement already satisfied: multiprocess>=0.70.16 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker) (0.70.16)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from schema->sagemaker) (21.6.0)\n",
      "Using cached sagemaker-2.221.1-py3-none-any.whl (1.5 MB)\n",
      "Installing collected packages: sagemaker\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.219.0\n",
      "    Uninstalling sagemaker-2.219.0:\n",
      "      Successfully uninstalled sagemaker-2.219.0\n",
      "Successfully installed sagemaker-2.221.1\n",
      "Collecting llava@ git+https://github.com/haotian-liu/LLaVA@v1.1.1 (from -r code/requirements.txt (line 1))\n",
      "  Cloning https://github.com/haotian-liu/LLaVA (to revision v1.1.1) to /tmp/pip-install-sfvrcqmh/llava_dd56adf0c7fb4518932e199a75659d1c\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/haotian-liu/LLaVA /tmp/pip-install-sfvrcqmh/llava_dd56adf0c7fb4518932e199a75659d1c\n",
      "  Running command git checkout -q 1619889c712e347be1cb4f78ec66e7cf414ac1a6\n",
      "  Resolved https://github.com/haotian-liu/LLaVA to commit 1619889c712e347be1cb4f78ec66e7cf414ac1a6\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: einops in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from llava@ git+https://github.com/haotian-liu/LLaVA@v1.1.1->-r code/requirements.txt (line 1)) (0.6.1)\n",
      "Requirement already satisfied: fastapi in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from llava@ git+https://github.com/haotian-liu/LLaVA@v1.1.1->-r code/requirements.txt (line 1)) (0.111.0)\n",
      "Collecting gradio==3.35.2 (from llava@ git+https://github.com/haotian-liu/LLaVA@v1.1.1->-r code/requirements.txt (line 1))\n",
      "  Downloading gradio-3.35.2-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: markdown2[all] in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from llava@ git+https://github.com/haotian-liu/LLaVA@v1.1.1->-r code/requirements.txt (line 1)) (2.4.13)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from llava@ git+https://github.com/haotian-liu/LLaVA@v1.1.1->-r code/requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from llava@ git+https://github.com/haotian-liu/LLaVA@v1.1.1->-r code/requirements.txt (line 1)) (2.31.0)\n",
      "Requirement already satisfied: sentencepiece in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from llava@ git+https://github.com/haotian-liu/LLaVA@v1.1.1->-r code/requirements.txt (line 1)) (0.1.99)\n",
      "Requirement already satisfied: tokenizers>=0.12.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from llava@ git+https://github.com/haotian-liu/LLaVA@v1.1.1->-r code/requirements.txt (line 1)) (0.15.1)\n",
      "Collecting torch==2.0.1 (from llava@ git+https://github.com/haotian-liu/LLaVA@v1.1.1->-r code/requirements.txt (line 1))\n",
      "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n",
      "Collecting torchvision==0.15.2 (from llava@ git+https://github.com/haotian-liu/LLaVA@v1.1.1->-r code/requirements.txt (line 1))\n",
      "  Downloading torchvision-0.15.2-cp310-cp310-manylinux1_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: uvicorn in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from llava@ git+https://github.com/haotian-liu/LLaVA@v1.1.1->-r code/requirements.txt (line 1)) (0.30.1)\n",
      "Requirement already satisfied: wandb in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from llava@ git+https://github.com/haotian-liu/LLaVA@v1.1.1->-r code/requirements.txt (line 1)) (0.17.0)\n",
      "Requirement already satisfied: shortuuid in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from llava@ git+https://github.com/haotian-liu/LLaVA@v1.1.1->-r code/requirements.txt (line 1)) (1.0.13)\n",
      "Requirement already satisfied: httpx==0.24.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from llava@ git+https://github.com/haotian-liu/LLaVA@v1.1.1->-r code/requirements.txt (line 1)) (0.24.0)\n",
      "Collecting deepspeed==0.9.5 (from llava@ git+https://github.com/haotian-liu/LLaVA@v1.1.1->-r code/requirements.txt (line 1))\n",
      "  Downloading deepspeed-0.9.5.tar.gz (809 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m809.9/809.9 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[41 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m [2024-06-05 08:30:02,993] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "  \u001b[31m   \u001b[0m /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/pydantic/_internal/_config.py:322: UserWarning: Valid config keys have changed in V2:\n",
      "  \u001b[31m   \u001b[0m * 'allow_population_by_field_name' has been renamed to 'populate_by_name'\n",
      "  \u001b[31m   \u001b[0m * 'validate_all' has been renamed to 'validate_default'\n",
      "  \u001b[31m   \u001b[0m   warnings.warn(message, UserWarning)\n",
      "  \u001b[31m   \u001b[0m /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/pydantic/_internal/_fields.py:151: UserWarning: Field \"model_persistence_threshold\" has conflict with protected namespace \"model_\".\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  \u001b[31m   \u001b[0m   warnings.warn(\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-sfvrcqmh/deepspeed_8dee97ec5749438c8bb8d3bfc0c28141/setup.py\", line 36, in <module>\n",
      "  \u001b[31m   \u001b[0m     from op_builder import get_default_compute_capabilities, OpBuilder\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-sfvrcqmh/deepspeed_8dee97ec5749438c8bb8d3bfc0c28141/op_builder/__init__.py\", line 18, in <module>\n",
      "  \u001b[31m   \u001b[0m     import deepspeed.ops.op_builder  # noqa: F401\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-sfvrcqmh/deepspeed_8dee97ec5749438c8bb8d3bfc0c28141/deepspeed/__init__.py\", line 16, in <module>\n",
      "  \u001b[31m   \u001b[0m     from . import module_inject\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-sfvrcqmh/deepspeed_8dee97ec5749438c8bb8d3bfc0c28141/deepspeed/module_inject/__init__.py\", line 6, in <module>\n",
      "  \u001b[31m   \u001b[0m     from .replace_module import replace_transformer_layer, revert_transformer_layer, ReplaceWithTensorSlicing, GroupQuantizer, generic_injection\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-sfvrcqmh/deepspeed_8dee97ec5749438c8bb8d3bfc0c28141/deepspeed/module_inject/replace_module.py\", line 792, in <module>\n",
      "  \u001b[31m   \u001b[0m     from ..pipe import PipelineModule\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-sfvrcqmh/deepspeed_8dee97ec5749438c8bb8d3bfc0c28141/deepspeed/pipe/__init__.py\", line 6, in <module>\n",
      "  \u001b[31m   \u001b[0m     from ..runtime.pipe import PipelineModule, LayerSpec, TiedLayerSpec\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-sfvrcqmh/deepspeed_8dee97ec5749438c8bb8d3bfc0c28141/deepspeed/runtime/pipe/__init__.py\", line 6, in <module>\n",
      "  \u001b[31m   \u001b[0m     from .module import PipelineModule, LayerSpec, TiedLayerSpec\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-sfvrcqmh/deepspeed_8dee97ec5749438c8bb8d3bfc0c28141/deepspeed/runtime/pipe/module.py\", line 19, in <module>\n",
      "  \u001b[31m   \u001b[0m     from ..activation_checkpointing import checkpointing\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-sfvrcqmh/deepspeed_8dee97ec5749438c8bb8d3bfc0c28141/deepspeed/runtime/activation_checkpointing/checkpointing.py\", line 25, in <module>\n",
      "  \u001b[31m   \u001b[0m     from deepspeed.runtime.config import DeepSpeedConfig\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-sfvrcqmh/deepspeed_8dee97ec5749438c8bb8d3bfc0c28141/deepspeed/runtime/config.py\", line 29, in <module>\n",
      "  \u001b[31m   \u001b[0m     from .zero.config import get_zero_config, ZeroStageEnum\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-sfvrcqmh/deepspeed_8dee97ec5749438c8bb8d3bfc0c28141/deepspeed/runtime/zero/__init__.py\", line 6, in <module>\n",
      "  \u001b[31m   \u001b[0m     from .partition_parameters import ZeroParamType\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-sfvrcqmh/deepspeed_8dee97ec5749438c8bb8d3bfc0c28141/deepspeed/runtime/zero/partition_parameters.py\", line 616, in <module>\n",
      "  \u001b[31m   \u001b[0m     class Init(InsertPostInitMethodToModuleSubClasses):\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-sfvrcqmh/deepspeed_8dee97ec5749438c8bb8d3bfc0c28141/deepspeed/runtime/zero/partition_parameters.py\", line 618, in Init\n",
      "  \u001b[31m   \u001b[0m     param_persistence_threshold = get_config_default(DeepSpeedZeroConfig, \"param_persistence_threshold\")\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-sfvrcqmh/deepspeed_8dee97ec5749438c8bb8d3bfc0c28141/deepspeed/runtime/config_utils.py\", line 116, in get_config_default\n",
      "  \u001b[31m   \u001b[0m     field_name).required, f\"'{field_name}' is a required field and does not have a default value\"\n",
      "  \u001b[31m   \u001b[0m AttributeError: 'FieldInfo' object has no attribute 'required'. Did you mean: 'is_required'?\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install sagemaker --upgrade\n",
    "!pip install -r code/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bundle llava model weights and code into a `model.tar.gz`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-west-2-726335585155/sagemaker-checkpoint-test/checkpoints-klook-0529-v2-10/generation_config.json to ./generation_config.json\n",
      "download: s3://sagemaker-us-west-2-726335585155/sagemaker-checkpoint-test/checkpoints-klook-0529-v2-10/config.json to ./config.json\n",
      "download: s3://sagemaker-us-west-2-726335585155/sagemaker-checkpoint-test/checkpoints-klook-0529-v2-10/model-00005-of-00006.safetensors to ./model-00005-of-00006.safetensors\n",
      "download: s3://sagemaker-us-west-2-726335585155/sagemaker-checkpoint-test/checkpoints-klook-0529-v2-10/model.safetensors.index.json to ./model.safetensors.index.json\n",
      "download: s3://sagemaker-us-west-2-726335585155/sagemaker-checkpoint-test/checkpoints-klook-0529-v2-10/model-00004-of-00006.safetensors to ./model-00004-of-00006.safetensors\n",
      "download: s3://sagemaker-us-west-2-726335585155/sagemaker-checkpoint-test/checkpoints-klook-0529-v2-10/special_tokens_map.json to ./special_tokens_map.json\n",
      "download: s3://sagemaker-us-west-2-726335585155/sagemaker-checkpoint-test/checkpoints-klook-0529-v2-10/tokenizer.model to ./tokenizer.model\n",
      "download: s3://sagemaker-us-west-2-726335585155/sagemaker-checkpoint-test/checkpoints-klook-0529-v2-10/tokenizer_config.json to ./tokenizer_config.json\n",
      "download: s3://sagemaker-us-west-2-726335585155/sagemaker-checkpoint-test/checkpoints-klook-0529-v2-10/trainer_state.json to ./trainer_state.json\n",
      "download: s3://sagemaker-us-west-2-726335585155/sagemaker-checkpoint-test/checkpoints-klook-0529-v2-10/training_args.bin to ./training_args.bin\n",
      "download: s3://sagemaker-us-west-2-726335585155/sagemaker-checkpoint-test/checkpoints-klook-0529-v2-10/model-00001-of-00006.safetensors to ./model-00001-of-00006.safetensors\n",
      "download: s3://sagemaker-us-west-2-726335585155/sagemaker-checkpoint-test/checkpoints-klook-0529-v2-10/model-00002-of-00006.safetensors to ./model-00002-of-00006.safetensors\n",
      "download: s3://sagemaker-us-west-2-726335585155/sagemaker-checkpoint-test/checkpoints-klook-0529-v2-10/model-00003-of-00006.safetensors to ./model-00003-of-00006.safetensors\n",
      "download: s3://sagemaker-us-west-2-726335585155/sagemaker-checkpoint-test/checkpoints-klook-0529-v2-10/model-00006-of-00006.safetensors to ./model-00006-of-00006.safetensors\n"
     ]
    }
   ],
   "source": [
    "#download model from s3 \n",
    "!aws s3 cp s3://sagemaker-us-west-2-726335585155/sagemaker-checkpoint-test/checkpoints-klook-0529-v2-10/ ./ --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tar: model.tar.gz: file changed as we read it\n"
     ]
    }
   ],
   "source": [
    "# Create SageMaker model.tar.gz artifact\n",
    "!tar -cf model.tar.gz --use-compress-program=pigz *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we created the `model.tar.gz` archive we can upload it to Amazon S3. We will use the `sagemaker` SDK to upload the model to our sagemaker session bucket.\n",
    "\n",
    "Initialize sagemaker session first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::726335585155:role/service-role/AmazonSageMakerServiceCatalogProductsUseRole\n",
      "sagemaker bucket: sagemaker-us-west-2-726335585155\n",
      "sagemaker session region: us-west-2\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    # setup your own rolename in sagemaker\n",
    "    role = iam.get_role(RoleName='AmazonSageMaker-ExecutionRole-20231008T201275')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delete: s3://sagemaker-us-west-2-726335585155/llava-v1.5-13b/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 rm s3://sagemaker-us-west-2-726335585155/llava-v1.5-13b/model.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the `model.tar.gz` to our sagemaker session bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Uploader\n",
    "\n",
    "# upload model.tar.gz to s3\n",
    "s3_model_uri = S3Uploader.upload(local_path=\"./model.tar.gz\", desired_s3_uri=f\"s3://{sess.default_bucket()}/llava-v1.5-13b-v1\")\n",
    "\n",
    "print(f\"model uploaded to: {s3_model_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use `HuggingfaceModel` to create our real-time inference endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "   model_data=s3_model_uri,      # path to your model and script\n",
    "   role=role,                    # iam role with permissions to create an Endpoint\n",
    "   transformers_version=\"4.28.1\",  # transformers version used\n",
    "   pytorch_version=\"2.0.0\",       # pytorch version used\n",
    "   py_version='py310',            # python version used\n",
    "   model_server_workers=1\n",
    ")\n",
    "\n",
    "# deploy the endpoint endpoint\n",
    "predictor = huggingface_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.g5.2xlarge\",\n",
    "    container_startup_health_check_timeout=600, # increase timeout for large models\n",
    "    model_data_download_timeout=600, # increase timeout for large models\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.deploy()` returns an `HuggingFacePredictor` object which can be used to request inference using the `.predict()` method. Our endpoint expects a `json` with at least `image` and `question` key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "data = {\n",
    "    \"image\" : 'https://raw.githubusercontent.com/haotian-liu/LLaVA/main/images/llava_logo.png', \n",
    "    \"question\" : \"Describe the image and color details.\",\n",
    "    # \"max_new_tokens\" : 1024,\n",
    "    # \"temperature\" : 0.2,\n",
    "    # \"stop_str\" : \"###\"\n",
    "}\n",
    "\n",
    "# request\n",
    "output = predictor.predict(data)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run inference with `llava` special token:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inference test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.04 ms, sys: 0 ns, total: 4.04 ms\n",
      "Wall time: 3.2 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Exterior</td>\n",
       "      <td>https://i.travelapi.com/lodging/1000000/920000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Exterior</td>\n",
       "      <td>https://res.klook.com/klook-hotel/image/upload...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Exterior</td>\n",
       "      <td>http://photos.hotelbeds.com/giata/bigger/75/75...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Exterior</td>\n",
       "      <td>https://res.klook.com/klook-hotel/image/upload...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Exterior</td>\n",
       "      <td>https://res.klook.com/klook-hotel/image/upload...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Exterior</td>\n",
       "      <td>https://q-xx.bstatic.com/xdata/images/hotel/ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Exterior</td>\n",
       "      <td>https://res.klook.com/klook-hotel/image/upload...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Exterior</td>\n",
       "      <td>https://res.klook.com/image/upload/v1662706162...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Exterior</td>\n",
       "      <td>https://i.travelapi.com/lodging/104000000/1030...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Exterior</td>\n",
       "      <td>https://res.klook.com/klook-hotel/image/upload...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                                url\n",
       "0  Exterior  https://i.travelapi.com/lodging/1000000/920000...\n",
       "1  Exterior  https://res.klook.com/klook-hotel/image/upload...\n",
       "2  Exterior  http://photos.hotelbeds.com/giata/bigger/75/75...\n",
       "3  Exterior  https://res.klook.com/klook-hotel/image/upload...\n",
       "4  Exterior  https://res.klook.com/klook-hotel/image/upload...\n",
       "5  Exterior  https://q-xx.bstatic.com/xdata/images/hotel/ma...\n",
       "6  Exterior  https://res.klook.com/klook-hotel/image/upload...\n",
       "7  Exterior  https://res.klook.com/image/upload/v1662706162...\n",
       "8  Exterior  https://i.travelapi.com/lodging/104000000/1030...\n",
       "9  Exterior  https://res.klook.com/klook-hotel/image/upload..."
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "## multiprocessing \n",
    "#g5.2xlarge\n",
    "#g5.4xlarge\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../../../../klook/data0527/original_hotel_image_data.csv')\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.1 ms, sys: 1.1 ms, total: 21.2 ms\n",
      "Wall time: 10.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "res = []\n",
    "for i in range(10):\n",
    "    img_path = df.iloc[i,1]\n",
    "    data = {\n",
    "    \"image\" : img_path, \n",
    "    \"question\" : \"Describe the image\",\n",
    "    # \"max_new_tokens\" : 1024,\n",
    "    # \"temperature\" : 0.2,\n",
    "    # \"stop_str\" : \"###\"\n",
    "}\n",
    "    \n",
    "    output = predictor.predict(data)\n",
    "    res.append(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_ls = []\n",
    "for i in range(10):\n",
    "    img_path = df.iloc[i,1]\n",
    "    data = {\n",
    "    \"image\" : img_path, \n",
    "    \"question\" : \"Describe the image\",}\n",
    "    input_ls.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-78:\n",
      "Exception ignored in: <Finalize object, dead>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/pool.py\", line 695, in _terminate_pool\n",
      "    cls._help_stuff_finish(inqueue, task_handler, len(pool))\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/pool.py\", line 675, in _help_stuff_finish\n",
      "    inqueue._rlock.acquire()\n",
      "KeyboardInterrupt: \n",
      "Process ForkPoolWorker-76:\n",
      "Process ForkPoolWorker-75:\n",
      "Process ForkPoolWorker-77:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/queues.py\", line 365, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50.1 ms, sys: 630 ms, total: 680 ms\n",
      "Wall time: 28min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "\n",
    "def process_function(data):\n",
    "    output = predictor.predict(data)\n",
    "    return output\n",
    "\n",
    "pool = multiprocessing.Pool(processes=4)  # Create a pool of 4 worker processes\n",
    "\n",
    "results = pool.map(process_function, input_ls)  # Apply process_function to range(10) in parallel\n",
    "\n",
    "pool.close()\n",
    "pool.join()  # Wait for all worker processes to finish\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/ec2-user/SageMaker/yafei/LLaVA/sagemaker/deploy']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inference ` predictor` can also be initilized like with your deployed `endpoint_name` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    # setup your own rolename in sagemaker\n",
    "    role = iam.get_role(RoleName='AmazonSageMaker-ExecutionRole-20231008T201275')['Role']['Arn']\n",
    "\n",
    "from sagemaker.huggingface.model import HuggingFacePredictor\n",
    "# initial the endpoint predictor\n",
    "predictor2 = HuggingFacePredictor(\n",
    "    endpoint_name=\"huggingface-pytorch-inference-2024-06-04-10-51-51-665\",\n",
    "    sagemaker_session=sess\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModelError",
     "evalue": "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received client error (400) from primary with message \"{\n  \"code\": 400,\n  \"type\": \"InternalServerException\",\n  \"message\": \"model_fn definition takes 1 or 2 arguments but 3 were given.\"\n}\n\". See https://us-west-2.console.aws.amazon.com/cloudwatch/home?region=us-west-2#logEventViewer:group=/aws/sagemaker/Endpoints/huggingface-pytorch-inference-2024-06-04-10-51-51-665 in account 726335585155 for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/haotian-liu/LLaVA/main/images/llava_logo.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m : image_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m : prompt}\n\u001b[0;32m----> 5\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(output)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/base_predictor.py:212\u001b[0m, in \u001b[0;36mPredictor.predict\u001b[0;34m(self, data, initial_args, target_model, target_variant, inference_id, custom_attributes, component_name)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inference_component_name:\n\u001b[1;32m    210\u001b[0m     request_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInferenceComponentName\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m inference_component_name\n\u001b[0;32m--> 212\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_runtime_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_response(response)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py:565\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    562\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    563\u001b[0m     )\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 565\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py:1021\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1017\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m error_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryErrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1018\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1019\u001b[0m     )\n\u001b[1;32m   1020\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1023\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mModelError\u001b[0m: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received client error (400) from primary with message \"{\n  \"code\": 400,\n  \"type\": \"InternalServerException\",\n  \"message\": \"model_fn definition takes 1 or 2 arguments but 3 were given.\"\n}\n\". See https://us-west-2.console.aws.amazon.com/cloudwatch/home?region=us-west-2#logEventViewer:group=/aws/sagemaker/Endpoints/huggingface-pytorch-inference-2024-06-04-10-51-51-665 in account 726335585155 for more information."
     ]
    }
   ],
   "source": [
    "raw_prompt = \"Describe the image and color details.\"\n",
    "prompt, stop_str = get_prompt(raw_prompt)\n",
    "image_path = \"https://raw.githubusercontent.com/haotian-liu/LLaVA/main/images/llava_logo.png\"\n",
    "data = {\"image\" : image_path, \"question\" : prompt}\n",
    "output = predictor2.predict(data)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To clean up, we can delete the model and endpoint by `delete_endpoint()`or using sagemaker console:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# delete sagemaker endpoint\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
